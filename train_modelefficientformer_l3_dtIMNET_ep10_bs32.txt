WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 3): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
Namespace(aa='rand-m9-mstd0.5-inc1', batch_size=32, clip_grad=0.01, clip_mode='agc', color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='/data1/datasets/imagenet', data_set='IMNET', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_eval=True, dist_url='env://', distillation_alpha=0.5, distillation_tau=1.0, distillation_type='hard', distributed=True, epochs=10, eval=False, finetune='', gpu=0, inat_category='name', input_size=224, lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='efficientformer_l3', model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, num_workers=8, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='modelefficientformer_l3_dtIMNET_ep10_bs32', patience_epochs=10, pin_mem=True, rank=0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='', sched='cosine', seed=0, smoothing=0.1, start_epoch=0, sync_bn=True, teacher_model='regnety_160', teacher_path='https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth', train_interpolation='bicubic', warmup_epochs=1, warmup_lr=1e-05, weight_decay=0.025, world_size=4)
/data1/dxw/conda_environment/efficientformer/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/data1/dxw/conda_environment/efficientformer/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/data1/dxw/conda_environment/efficientformer/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/data1/dxw/conda_environment/efficientformer/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
Creating model: efficientformer_l3
number of params: 31406000
Creating teacher model: regnety_160
Start training for 10 epochs
Epoch: [0]  [    0/10008]  eta: 20:57:28  lr: 0.000010  loss: 6.9311 (6.9311)  time: 7.5388  data: 1.7615  max mem: 13702
Epoch: [0]  [  100/10008]  eta: 1:12:15  lr: 0.000010  loss: 6.9117 (6.9181)  time: 0.3815  data: 0.0002  max mem: 13702
Epoch: [0]  [  200/10008]  eta: 1:05:17  lr: 0.000010  loss: 6.9092 (6.9147)  time: 0.3636  data: 0.0002  max mem: 13702
Epoch: [0]  [  300/10008]  eta: 1:03:00  lr: 0.000010  loss: 6.9032 (6.9121)  time: 0.3400  data: 0.0002  max mem: 13702
Epoch: [0]  [  400/10008]  eta: 1:00:59  lr: 0.000010  loss: 6.8992 (6.9090)  time: 0.3711  data: 0.0002  max mem: 13702
Epoch: [0]  [  500/10008]  eta: 0:59:35  lr: 0.000010  loss: 6.8962 (6.9068)  time: 0.3514  data: 0.0002  max mem: 13702
Epoch: [0]  [  600/10008]  eta: 0:58:36  lr: 0.000010  loss: 6.8895 (6.9050)  time: 0.3554  data: 0.0002  max mem: 13702
Epoch: [0]  [  700/10008]  eta: 0:57:52  lr: 0.000010  loss: 6.8935 (6.9034)  time: 0.4149  data: 0.0002  max mem: 13702
Epoch: [0]  [  800/10008]  eta: 0:57:24  lr: 0.000010  loss: 6.8869 (6.9016)  time: 0.3972  data: 0.0003  max mem: 13702
Epoch: [0]  [  900/10008]  eta: 0:57:01  lr: 0.000010  loss: 6.8887 (6.9000)  time: 0.3935  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1000/10008]  eta: 0:56:31  lr: 0.000010  loss: 6.8785 (6.8983)  time: 0.3898  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1100/10008]  eta: 0:55:52  lr: 0.000010  loss: 6.8853 (6.8968)  time: 0.3744  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1200/10008]  eta: 0:55:18  lr: 0.000010  loss: 6.8943 (6.8958)  time: 0.4035  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1300/10008]  eta: 0:54:44  lr: 0.000010  loss: 6.8878 (6.8949)  time: 0.3749  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1400/10008]  eta: 0:54:07  lr: 0.000010  loss: 6.8820 (6.8941)  time: 0.3806  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1500/10008]  eta: 0:53:30  lr: 0.000010  loss: 6.8741 (6.8930)  time: 0.3803  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1600/10008]  eta: 0:52:55  lr: 0.000010  loss: 6.8745 (6.8921)  time: 0.3795  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1700/10008]  eta: 0:52:20  lr: 0.000010  loss: 6.8767 (6.8910)  time: 0.4080  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1800/10008]  eta: 0:51:41  lr: 0.000010  loss: 6.8842 (6.8904)  time: 0.3796  data: 0.0002  max mem: 13702
Epoch: [0]  [ 1900/10008]  eta: 0:51:05  lr: 0.000010  loss: 6.8750 (6.8897)  time: 0.3817  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2000/10008]  eta: 0:50:29  lr: 0.000010  loss: 6.8623 (6.8888)  time: 0.3748  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2100/10008]  eta: 0:49:55  lr: 0.000010  loss: 6.8756 (6.8882)  time: 0.3828  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2200/10008]  eta: 0:49:20  lr: 0.000010  loss: 6.8669 (6.8875)  time: 0.3682  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2300/10008]  eta: 0:48:51  lr: 0.000010  loss: 6.8797 (6.8871)  time: 0.3946  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2400/10008]  eta: 0:48:13  lr: 0.000010  loss: 6.8713 (6.8866)  time: 0.3697  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2500/10008]  eta: 0:47:35  lr: 0.000010  loss: 6.8702 (6.8860)  time: 0.3681  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2600/10008]  eta: 0:46:56  lr: 0.000010  loss: 6.8595 (6.8854)  time: 0.3979  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2700/10008]  eta: 0:46:20  lr: 0.000010  loss: 6.8665 (6.8850)  time: 0.3895  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2800/10008]  eta: 0:45:41  lr: 0.000010  loss: 6.8757 (6.8844)  time: 0.3749  data: 0.0002  max mem: 13702
Epoch: [0]  [ 2900/10008]  eta: 0:45:02  lr: 0.000010  loss: 6.8614 (6.8839)  time: 0.3715  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3000/10008]  eta: 0:44:24  lr: 0.000010  loss: 6.8758 (6.8836)  time: 0.3824  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3100/10008]  eta: 0:43:45  lr: 0.000010  loss: 6.8718 (6.8832)  time: 0.3848  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3200/10008]  eta: 0:43:08  lr: 0.000010  loss: 6.8751 (6.8829)  time: 0.4010  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3300/10008]  eta: 0:42:28  lr: 0.000010  loss: 6.8685 (6.8826)  time: 0.3511  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3400/10008]  eta: 0:41:46  lr: 0.000010  loss: 6.8692 (6.8823)  time: 0.3520  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3500/10008]  eta: 0:41:08  lr: 0.000010  loss: 6.8630 (6.8818)  time: 0.3839  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3600/10008]  eta: 0:40:32  lr: 0.000010  loss: 6.8777 (6.8816)  time: 0.3883  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3700/10008]  eta: 0:39:54  lr: 0.000010  loss: 6.8710 (6.8813)  time: 0.3713  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3800/10008]  eta: 0:39:18  lr: 0.000010  loss: 6.8765 (6.8811)  time: 0.3923  data: 0.0002  max mem: 13702
Epoch: [0]  [ 3900/10008]  eta: 0:38:42  lr: 0.000010  loss: 6.8691 (6.8808)  time: 0.3993  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4000/10008]  eta: 0:38:04  lr: 0.000010  loss: 6.8598 (6.8805)  time: 0.3770  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4100/10008]  eta: 0:37:26  lr: 0.000010  loss: 6.8615 (6.8801)  time: 0.3734  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4200/10008]  eta: 0:36:48  lr: 0.000010  loss: 6.8630 (6.8798)  time: 0.3756  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4300/10008]  eta: 0:36:10  lr: 0.000010  loss: 6.8657 (6.8796)  time: 0.3897  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4400/10008]  eta: 0:35:32  lr: 0.000010  loss: 6.8686 (6.8793)  time: 0.3893  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4500/10008]  eta: 0:34:55  lr: 0.000010  loss: 6.8688 (6.8791)  time: 0.3751  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4600/10008]  eta: 0:34:19  lr: 0.000010  loss: 6.8692 (6.8788)  time: 0.3935  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4700/10008]  eta: 0:33:41  lr: 0.000010  loss: 6.8714 (6.8784)  time: 0.3827  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4800/10008]  eta: 0:33:03  lr: 0.000010  loss: 6.8694 (6.8781)  time: 0.3801  data: 0.0002  max mem: 13702
Epoch: [0]  [ 4900/10008]  eta: 0:32:26  lr: 0.000010  loss: 6.8649 (6.8778)  time: 0.4137  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5000/10008]  eta: 0:31:48  lr: 0.000010  loss: 6.8667 (6.8775)  time: 0.3814  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5100/10008]  eta: 0:31:12  lr: 0.000010  loss: 6.8641 (6.8772)  time: 0.3922  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5200/10008]  eta: 0:30:35  lr: 0.000010  loss: 6.8675 (6.8770)  time: 0.4141  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5300/10008]  eta: 0:29:56  lr: 0.000010  loss: 6.8558 (6.8767)  time: 0.3843  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5400/10008]  eta: 0:29:19  lr: 0.000010  loss: 6.8615 (6.8763)  time: 0.3850  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5500/10008]  eta: 0:28:42  lr: 0.000010  loss: 6.8610 (6.8760)  time: 0.3999  data: 0.0003  max mem: 13702
Epoch: [0]  [ 5600/10008]  eta: 0:28:05  lr: 0.000010  loss: 6.8575 (6.8757)  time: 0.4026  data: 0.0003  max mem: 13702
Epoch: [0]  [ 5700/10008]  eta: 0:27:28  lr: 0.000010  loss: 6.8589 (6.8753)  time: 0.3896  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5800/10008]  eta: 0:26:51  lr: 0.000010  loss: 6.8569 (6.8750)  time: 0.3942  data: 0.0002  max mem: 13702
Epoch: [0]  [ 5900/10008]  eta: 0:26:14  lr: 0.000010  loss: 6.8526 (6.8747)  time: 0.3794  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6000/10008]  eta: 0:25:36  lr: 0.000010  loss: 6.8421 (6.8744)  time: 0.3909  data: 0.0003  max mem: 13702
Epoch: [0]  [ 6100/10008]  eta: 0:24:58  lr: 0.000010  loss: 6.8542 (6.8741)  time: 0.3963  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6200/10008]  eta: 0:24:21  lr: 0.000010  loss: 6.8531 (6.8737)  time: 0.3780  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6300/10008]  eta: 0:23:43  lr: 0.000010  loss: 6.8568 (6.8734)  time: 0.3816  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6400/10008]  eta: 0:23:06  lr: 0.000010  loss: 6.8489 (6.8730)  time: 0.4566  data: 0.0544  max mem: 13702
Epoch: [0]  [ 6500/10008]  eta: 0:22:28  lr: 0.000010  loss: 6.8521 (6.8727)  time: 0.3960  data: 0.0003  max mem: 13702
Epoch: [0]  [ 6600/10008]  eta: 0:21:50  lr: 0.000010  loss: 6.8331 (6.8724)  time: 0.3913  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6700/10008]  eta: 0:21:12  lr: 0.000010  loss: 6.8514 (6.8721)  time: 0.4100  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6800/10008]  eta: 0:20:34  lr: 0.000010  loss: 6.8432 (6.8717)  time: 0.3793  data: 0.0002  max mem: 13702
Epoch: [0]  [ 6900/10008]  eta: 0:19:57  lr: 0.000010  loss: 6.8527 (6.8714)  time: 0.4091  data: 0.0003  max mem: 13702
Epoch: [0]  [ 7000/10008]  eta: 0:19:18  lr: 0.000010  loss: 6.8411 (6.8710)  time: 0.3876  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7100/10008]  eta: 0:18:40  lr: 0.000010  loss: 6.8542 (6.8707)  time: 0.3867  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7200/10008]  eta: 0:18:02  lr: 0.000010  loss: 6.8518 (6.8704)  time: 0.3971  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7300/10008]  eta: 0:17:24  lr: 0.000010  loss: 6.8531 (6.8701)  time: 0.3934  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7400/10008]  eta: 0:16:46  lr: 0.000010  loss: 6.8403 (6.8697)  time: 0.3855  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7500/10008]  eta: 0:16:08  lr: 0.000010  loss: 6.8494 (6.8695)  time: 0.3912  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7600/10008]  eta: 0:15:29  lr: 0.000010  loss: 6.8392 (6.8691)  time: 0.3915  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7700/10008]  eta: 0:14:50  lr: 0.000010  loss: 6.8541 (6.8688)  time: 0.3802  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7800/10008]  eta: 0:14:12  lr: 0.000010  loss: 6.8277 (6.8684)  time: 0.3857  data: 0.0002  max mem: 13702
Epoch: [0]  [ 7900/10008]  eta: 0:13:33  lr: 0.000010  loss: 6.8375 (6.8681)  time: 0.3923  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8000/10008]  eta: 0:12:55  lr: 0.000010  loss: 6.8376 (6.8678)  time: 0.3843  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8100/10008]  eta: 0:12:17  lr: 0.000010  loss: 6.8495 (6.8675)  time: 0.3986  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8200/10008]  eta: 0:11:38  lr: 0.000010  loss: 6.8393 (6.8671)  time: 0.3976  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8300/10008]  eta: 0:11:00  lr: 0.000010  loss: 6.8385 (6.8668)  time: 0.3910  data: 0.0005  max mem: 13702
Epoch: [0]  [ 8400/10008]  eta: 0:10:21  lr: 0.000010  loss: 6.8366 (6.8665)  time: 0.3871  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8500/10008]  eta: 0:09:43  lr: 0.000010  loss: 6.8360 (6.8662)  time: 0.3883  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8600/10008]  eta: 0:09:04  lr: 0.000010  loss: 6.8279 (6.8659)  time: 0.3826  data: 0.0002  max mem: 13702
Epoch: [0]  [ 8700/10008]  eta: 0:08:25  lr: 0.000010  loss: 6.8329 (6.8656)  time: 0.3877  data: 0.0002  max mem: 13702
