2024-06-05 17:23:34,352 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA GeForce RTX 4090 D
CUDA_HOME: /usr/local/cuda-12.2
NVCC: Cuda compilation tools, release 12.2, V12.2.140
GCC: gcc (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0
PyTorch: 1.12.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.0+cu113
OpenCV: 4.9.0
MMCV: 1.6.1
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.25.1+4bb7153
------------------------------------------------------------

2024-06-05 17:23:34,595 - mmdet - INFO - Distributed training: True
2024-06-05 17:23:34,940 - mmdet - INFO - Config:
model = dict(
    type='MaskRCNN',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='efficientformer_l1_feat',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(
            type='Pretrained',
            checkpoint='../weights/efficientformer_l1_300d.pth')),
    neck=dict(
        type='FPN',
        in_channels=[48, 96, 224, 448],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=80,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_head=dict(
            type='FCNMaskHead',
            num_convs=4,
            in_channels=256,
            conv_out_channels=256,
            num_classes=80,
            loss_mask=dict(
                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            mask_size=28,
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100,
            mask_thr_binary=0.5)))
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_train2017.json',
        img_prefix='data/coco/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(metric=['bbox', 'segm'])
optimizer = dict(type='AdamW', lr=0.0002, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=1e-06,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/mask_rcnn_efficientformer_l1_fpn_1x_coco'
auto_resume = False
gpu_ids = range(0, 4)

2024-06-05 17:23:34,940 - mmdet - INFO - Set random seed to 0, deterministic: False
2024-06-05 17:23:35,291 - mmdet - INFO - load checkpoint from local path: ../weights/efficientformer_l1_300d.pth
2024-06-05 17:23:35,799 - mmdet - INFO - load checkpoint from local path: ../weights/efficientformer_l1_300d.pth
2024-06-05 17:23:36,002 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2024-06-05 17:23:36,021 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2024-06-05 17:23:36,026 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.patch_embed.0.weight - torch.Size([24, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.1.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.1.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.3.weight - torch.Size([48, 24, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.3.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.4.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.4.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.layer_scale_1 - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.layer_scale_2 - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.fc1.weight - torch.Size([192, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.fc1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.fc2.weight - torch.Size([48, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.fc2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.norm2.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.0.mlp.norm2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.layer_scale_1 - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.layer_scale_2 - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.fc1.weight - torch.Size([192, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.fc1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.fc2.weight - torch.Size([48, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.fc2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.norm2.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.1.mlp.norm2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.layer_scale_1 - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.layer_scale_2 - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.fc1.weight - torch.Size([192, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.fc1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.fc2.weight - torch.Size([48, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.fc2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.norm2.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.0.2.mlp.norm2.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.1.proj.weight - torch.Size([96, 48, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.1.proj.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.1.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.1.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.layer_scale_1 - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.layer_scale_2 - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.fc1.weight - torch.Size([384, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.fc1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.fc2.weight - torch.Size([96, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.fc2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.0.mlp.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.layer_scale_1 - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.layer_scale_2 - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.fc1.weight - torch.Size([384, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.fc1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.fc2.weight - torch.Size([96, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.fc2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.2.1.mlp.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.3.proj.weight - torch.Size([224, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.3.proj.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.3.norm.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.3.norm.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.layer_scale_1 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.layer_scale_2 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.fc1.weight - torch.Size([896, 224, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.fc1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.fc2.weight - torch.Size([224, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.fc2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.norm1.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.norm1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.norm2.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.0.mlp.norm2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.layer_scale_1 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.layer_scale_2 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.fc1.weight - torch.Size([896, 224, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.fc1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.fc2.weight - torch.Size([224, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.fc2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.norm1.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.norm1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.norm2.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.1.mlp.norm2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.layer_scale_1 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.layer_scale_2 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.fc1.weight - torch.Size([896, 224, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.fc1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.fc2.weight - torch.Size([224, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.fc2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.norm1.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.norm1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.norm2.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.2.mlp.norm2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.layer_scale_1 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.layer_scale_2 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.fc1.weight - torch.Size([896, 224, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.fc1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.fc2.weight - torch.Size([224, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.fc2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.norm1.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.norm1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.norm2.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.3.mlp.norm2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.layer_scale_1 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.layer_scale_2 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.fc1.weight - torch.Size([896, 224, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.fc1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.fc2.weight - torch.Size([224, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.fc2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.norm1.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.norm1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.norm2.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.4.mlp.norm2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.layer_scale_1 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.layer_scale_2 - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.fc1.weight - torch.Size([896, 224, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.fc1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.fc2.weight - torch.Size([224, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.fc2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.norm1.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.norm1.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.norm2.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.4.5.mlp.norm2.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.5.proj.weight - torch.Size([448, 224, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.5.proj.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.5.norm.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.5.norm.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.layer_scale_1 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.layer_scale_2 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.fc1.weight - torch.Size([1792, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.fc1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.fc2.weight - torch.Size([448, 1792, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.fc2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.norm1.weight - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.norm1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.norm2.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.0.mlp.norm2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.layer_scale_1 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.layer_scale_2 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.fc1.weight - torch.Size([1792, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.fc1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.fc2.weight - torch.Size([448, 1792, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.fc2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.norm1.weight - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.norm1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.norm2.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.1.mlp.norm2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.layer_scale_1 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.layer_scale_2 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.fc1.weight - torch.Size([1792, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.fc1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.fc2.weight - torch.Size([448, 1792, 1, 1]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.fc2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.norm1.weight - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.norm1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.norm2.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.2.mlp.norm2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.layer_scale_1 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.layer_scale_2 - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.norm1.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.norm1.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.token_mixer.attention_biases_seg - torch.Size([8, 625]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.token_mixer.qkv.weight - torch.Size([1536, 448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.token_mixer.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.token_mixer.proj.weight - torch.Size([448, 1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.token_mixer.proj.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.norm2.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.norm2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.mlp.fc1.weight - torch.Size([1792, 448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.mlp.fc1.bias - torch.Size([1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.mlp.fc2.weight - torch.Size([448, 1792]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.network.6.4.mlp.fc2.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm0.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm0.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm4.weight - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm4.bias - torch.Size([224]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm6.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.norm6.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 48, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 224, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 448, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.upsample.weight - torch.Size([256, 256, 2, 2]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.upsample.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.bias - torch.Size([80]): 
Initialized by user-defined `init_weights` in FCNMaskHead  
2024-06-05 17:24:01,694 - mmdet - INFO - Start running, host: expuser@xmu-SMRI, work_dir: /home/expuser/Documents/EfficientFormer/detection/work_dirs/mask_rcnn_efficientformer_l1_fpn_1x_coco
2024-06-05 17:24:01,694 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) DistEvalHook                       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-06-05 17:24:01,695 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2024-06-05 17:24:01,695 - mmdet - INFO - Checkpoints will be saved to /home/expuser/Documents/EfficientFormer/detection/work_dirs/mask_rcnn_efficientformer_l1_fpn_1x_coco by HardDiskBackend.
2024-06-05 17:25:22,015 - mmdet - INFO - Epoch [1][50/3665]	lr: 1.960e-05, eta: 19:36:00, time: 1.606, data_time: 0.439, memory: 19844, loss_rpn_cls: 0.6134, loss_rpn_bbox: 0.1051, loss_cls: 2.1247, acc: 71.3268, loss_bbox: 0.0499, loss_mask: 0.8032, loss: 3.6962
2024-06-05 17:26:19,319 - mmdet - INFO - Epoch [1][100/3665]	lr: 3.960e-05, eta: 16:46:24, time: 1.146, data_time: 0.311, memory: 19844, loss_rpn_cls: 0.2867, loss_rpn_bbox: 0.1020, loss_cls: 0.5093, acc: 94.0371, loss_bbox: 0.2025, loss_mask: 0.6992, loss: 1.7997
2024-06-05 17:27:14,965 - mmdet - INFO - Epoch [1][150/3665]	lr: 5.960e-05, eta: 15:41:09, time: 1.113, data_time: 0.302, memory: 19844, loss_rpn_cls: 0.1933, loss_rpn_bbox: 0.0972, loss_cls: 0.4139, acc: 93.8505, loss_bbox: 0.2096, loss_mask: 0.6742, loss: 1.5881
2024-06-05 17:28:08,930 - mmdet - INFO - Epoch [1][200/3665]	lr: 7.960e-05, eta: 15:01:56, time: 1.079, data_time: 0.240, memory: 19844, loss_rpn_cls: 0.1557, loss_rpn_bbox: 0.0913, loss_cls: 0.3889, acc: 93.8683, loss_bbox: 0.2109, loss_mask: 0.6392, loss: 1.4861
2024-06-05 17:29:02,430 - mmdet - INFO - Epoch [1][250/3665]	lr: 9.960e-05, eta: 14:36:41, time: 1.070, data_time: 0.254, memory: 19844, loss_rpn_cls: 0.1356, loss_rpn_bbox: 0.0940, loss_cls: 0.4023, acc: 93.1510, loss_bbox: 0.2421, loss_mask: 0.5944, loss: 1.4685
2024-06-05 17:29:56,636 - mmdet - INFO - Epoch [1][300/3665]	lr: 1.196e-04, eta: 14:21:16, time: 1.084, data_time: 0.241, memory: 19844, loss_rpn_cls: 0.1159, loss_rpn_bbox: 0.0893, loss_cls: 0.4610, acc: 91.5726, loss_bbox: 0.3104, loss_mask: 0.5423, loss: 1.5189
2024-06-05 17:30:51,488 - mmdet - INFO - Epoch [1][350/3665]	lr: 1.396e-04, eta: 14:11:21, time: 1.097, data_time: 0.228, memory: 19844, loss_rpn_cls: 0.0987, loss_rpn_bbox: 0.0911, loss_cls: 0.4637, acc: 91.1167, loss_bbox: 0.3272, loss_mask: 0.5002, loss: 1.4809
2024-06-05 17:31:45,912 - mmdet - INFO - Epoch [1][400/3665]	lr: 1.596e-04, eta: 14:02:54, time: 1.089, data_time: 0.259, memory: 19844, loss_rpn_cls: 0.0921, loss_rpn_bbox: 0.0844, loss_cls: 0.4631, acc: 90.4215, loss_bbox: 0.3462, loss_mask: 0.4714, loss: 1.4572
2024-06-05 17:32:42,647 - mmdet - INFO - Epoch [1][450/3665]	lr: 1.796e-04, eta: 13:59:50, time: 1.134, data_time: 0.285, memory: 19844, loss_rpn_cls: 0.0874, loss_rpn_bbox: 0.0834, loss_cls: 0.4536, acc: 89.9800, loss_bbox: 0.3513, loss_mask: 0.4508, loss: 1.4265
2024-06-05 17:33:53,214 - mmdet - INFO - Epoch [1][500/3665]	lr: 1.996e-04, eta: 14:17:17, time: 1.412, data_time: 0.352, memory: 19844, loss_rpn_cls: 0.0814, loss_rpn_bbox: 0.0831, loss_cls: 0.4299, acc: 89.8630, loss_bbox: 0.3612, loss_mask: 0.4382, loss: 1.3937
2024-06-05 17:34:47,318 - mmdet - INFO - Epoch [1][550/3665]	lr: 2.000e-04, eta: 14:09:38, time: 1.082, data_time: 0.239, memory: 19844, loss_rpn_cls: 0.0791, loss_rpn_bbox: 0.0797, loss_cls: 0.3974, acc: 90.2306, loss_bbox: 0.3482, loss_mask: 0.4253, loss: 1.3296
2024-06-05 17:35:42,822 - mmdet - INFO - Epoch [1][600/3665]	lr: 2.000e-04, eta: 14:04:50, time: 1.110, data_time: 0.268, memory: 19844, loss_rpn_cls: 0.0749, loss_rpn_bbox: 0.0805, loss_cls: 0.3922, acc: 89.8414, loss_bbox: 0.3577, loss_mask: 0.4066, loss: 1.3120
2024-06-05 17:36:40,626 - mmdet - INFO - Epoch [1][650/3665]	lr: 2.000e-04, eta: 14:03:10, time: 1.156, data_time: 0.268, memory: 19844, loss_rpn_cls: 0.0772, loss_rpn_bbox: 0.0795, loss_cls: 0.3747, acc: 89.9469, loss_bbox: 0.3522, loss_mask: 0.4016, loss: 1.2852
2024-06-05 17:37:35,090 - mmdet - INFO - Epoch [1][700/3665]	lr: 2.000e-04, eta: 13:58:09, time: 1.089, data_time: 0.242, memory: 19844, loss_rpn_cls: 0.0708, loss_rpn_bbox: 0.0771, loss_cls: 0.3652, acc: 90.0819, loss_bbox: 0.3454, loss_mask: 0.3942, loss: 1.2526
2024-06-05 17:38:32,051 - mmdet - INFO - Epoch [1][750/3665]	lr: 2.000e-04, eta: 13:56:06, time: 1.139, data_time: 0.254, memory: 19844, loss_rpn_cls: 0.0715, loss_rpn_bbox: 0.0777, loss_cls: 0.3654, acc: 89.8053, loss_bbox: 0.3596, loss_mask: 0.3841, loss: 1.2582
2024-06-05 17:39:28,104 - mmdet - INFO - Epoch [1][800/3665]	lr: 2.000e-04, eta: 13:53:21, time: 1.121, data_time: 0.265, memory: 19844, loss_rpn_cls: 0.0705, loss_rpn_bbox: 0.0777, loss_cls: 0.3541, acc: 89.9321, loss_bbox: 0.3474, loss_mask: 0.3788, loss: 1.2284
2024-06-05 17:40:23,356 - mmdet - INFO - Epoch [1][850/3665]	lr: 2.000e-04, eta: 13:50:09, time: 1.105, data_time: 0.250, memory: 19844, loss_rpn_cls: 0.0682, loss_rpn_bbox: 0.0743, loss_cls: 0.3542, acc: 89.8367, loss_bbox: 0.3500, loss_mask: 0.3771, loss: 1.2239
2024-06-05 17:41:17,294 - mmdet - INFO - Epoch [1][900/3665]	lr: 2.000e-04, eta: 13:46:09, time: 1.079, data_time: 0.236, memory: 19844, loss_rpn_cls: 0.0662, loss_rpn_bbox: 0.0771, loss_cls: 0.3400, acc: 90.2476, loss_bbox: 0.3387, loss_mask: 0.3733, loss: 1.1954
2024-06-05 17:42:12,280 - mmdet - INFO - Epoch [1][950/3665]	lr: 2.000e-04, eta: 13:43:16, time: 1.100, data_time: 0.238, memory: 19844, loss_rpn_cls: 0.0689, loss_rpn_bbox: 0.0774, loss_cls: 0.3454, acc: 89.9296, loss_bbox: 0.3488, loss_mask: 0.3725, loss: 1.2129
2024-06-05 17:43:05,492 - mmdet - INFO - Exp name: mask_rcnn_efficientformer_l1_fpn_1x_coco.py
2024-06-05 17:43:05,492 - mmdet - INFO - Epoch [1][1000/3665]	lr: 2.000e-04, eta: 13:39:19, time: 1.064, data_time: 0.240, memory: 19844, loss_rpn_cls: 0.0672, loss_rpn_bbox: 0.0724, loss_cls: 0.3284, acc: 90.3560, loss_bbox: 0.3314, loss_mask: 0.3607, loss: 1.1600
2024-06-05 17:44:00,934 - mmdet - INFO - Epoch [1][1050/3665]	lr: 2.000e-04, eta: 13:37:10, time: 1.109, data_time: 0.263, memory: 19844, loss_rpn_cls: 0.0676, loss_rpn_bbox: 0.0773, loss_cls: 0.3381, acc: 89.9468, loss_bbox: 0.3420, loss_mask: 0.3644, loss: 1.1894
2024-06-05 17:44:56,387 - mmdet - INFO - Epoch [1][1100/3665]	lr: 2.000e-04, eta: 13:35:09, time: 1.109, data_time: 0.250, memory: 19844, loss_rpn_cls: 0.0684, loss_rpn_bbox: 0.0743, loss_cls: 0.3314, acc: 90.2578, loss_bbox: 0.3297, loss_mask: 0.3589, loss: 1.1628
2024-06-05 17:45:49,739 - mmdet - INFO - Epoch [1][1150/3665]	lr: 2.000e-04, eta: 13:31:55, time: 1.067, data_time: 0.233, memory: 19844, loss_rpn_cls: 0.0631, loss_rpn_bbox: 0.0710, loss_cls: 0.3187, acc: 90.5115, loss_bbox: 0.3252, loss_mask: 0.3546, loss: 1.1327
2024-06-05 17:46:42,932 - mmdet - INFO - Epoch [1][1200/3665]	lr: 2.000e-04, eta: 13:28:46, time: 1.064, data_time: 0.224, memory: 19844, loss_rpn_cls: 0.0605, loss_rpn_bbox: 0.0729, loss_cls: 0.3220, acc: 90.3235, loss_bbox: 0.3311, loss_mask: 0.3549, loss: 1.1414
2024-06-05 17:47:36,420 - mmdet - INFO - Epoch [1][1250/3665]	lr: 2.000e-04, eta: 13:26:00, time: 1.070, data_time: 0.221, memory: 19844, loss_rpn_cls: 0.0629, loss_rpn_bbox: 0.0729, loss_cls: 0.3123, acc: 90.5862, loss_bbox: 0.3284, loss_mask: 0.3542, loss: 1.1308
2024-06-05 17:48:30,002 - mmdet - INFO - Epoch [1][1300/3665]	lr: 2.000e-04, eta: 13:23:24, time: 1.072, data_time: 0.240, memory: 19844, loss_rpn_cls: 0.0626, loss_rpn_bbox: 0.0711, loss_cls: 0.3198, acc: 90.1971, loss_bbox: 0.3390, loss_mask: 0.3492, loss: 1.1417
2024-06-05 17:49:24,650 - mmdet - INFO - Epoch [1][1350/3665]	lr: 2.000e-04, eta: 13:21:30, time: 1.093, data_time: 0.234, memory: 19844, loss_rpn_cls: 0.0654, loss_rpn_bbox: 0.0753, loss_cls: 0.3211, acc: 90.1909, loss_bbox: 0.3355, loss_mask: 0.3530, loss: 1.1503
2024-06-05 17:50:18,119 - mmdet - INFO - Epoch [1][1400/3665]	lr: 2.000e-04, eta: 13:19:04, time: 1.069, data_time: 0.251, memory: 19844, loss_rpn_cls: 0.0631, loss_rpn_bbox: 0.0714, loss_cls: 0.3164, acc: 90.3480, loss_bbox: 0.3283, loss_mask: 0.3471, loss: 1.1262
2024-06-05 17:51:10,898 - mmdet - INFO - Epoch [1][1450/3665]	lr: 2.000e-04, eta: 13:16:25, time: 1.056, data_time: 0.227, memory: 19844, loss_rpn_cls: 0.0595, loss_rpn_bbox: 0.0678, loss_cls: 0.3013, acc: 90.8257, loss_bbox: 0.3148, loss_mask: 0.3413, loss: 1.0847
2024-06-05 17:52:05,209 - mmdet - INFO - Epoch [1][1500/3665]	lr: 2.000e-04, eta: 13:14:36, time: 1.086, data_time: 0.290, memory: 19844, loss_rpn_cls: 0.0612, loss_rpn_bbox: 0.0729, loss_cls: 0.3220, acc: 90.0416, loss_bbox: 0.3377, loss_mask: 0.3460, loss: 1.1398
2024-06-05 17:52:59,799 - mmdet - INFO - Epoch [1][1550/3665]	lr: 2.000e-04, eta: 13:12:58, time: 1.092, data_time: 0.273, memory: 19844, loss_rpn_cls: 0.0621, loss_rpn_bbox: 0.0735, loss_cls: 0.3094, acc: 90.5298, loss_bbox: 0.3290, loss_mask: 0.3465, loss: 1.1205
2024-06-05 17:53:54,647 - mmdet - INFO - Epoch [1][1600/3665]	lr: 2.000e-04, eta: 13:11:30, time: 1.097, data_time: 0.235, memory: 19844, loss_rpn_cls: 0.0611, loss_rpn_bbox: 0.0707, loss_cls: 0.3128, acc: 90.4182, loss_bbox: 0.3278, loss_mask: 0.3411, loss: 1.1134
2024-06-05 17:54:48,446 - mmdet - INFO - Epoch [1][1650/3665]	lr: 2.000e-04, eta: 13:09:36, time: 1.076, data_time: 0.262, memory: 19844, loss_rpn_cls: 0.0607, loss_rpn_bbox: 0.0713, loss_cls: 0.3149, acc: 90.2172, loss_bbox: 0.3280, loss_mask: 0.3346, loss: 1.1094
2024-06-05 17:55:42,817 - mmdet - INFO - Epoch [1][1700/3665]	lr: 2.000e-04, eta: 13:08:01, time: 1.087, data_time: 0.242, memory: 19844, loss_rpn_cls: 0.0614, loss_rpn_bbox: 0.0717, loss_cls: 0.3060, acc: 90.4994, loss_bbox: 0.3241, loss_mask: 0.3358, loss: 1.0990
2024-06-05 17:56:37,573 - mmdet - INFO - Epoch [1][1750/3665]	lr: 2.000e-04, eta: 13:06:37, time: 1.095, data_time: 0.252, memory: 19844, loss_rpn_cls: 0.0588, loss_rpn_bbox: 0.0716, loss_cls: 0.3076, acc: 90.4702, loss_bbox: 0.3215, loss_mask: 0.3359, loss: 1.0954
2024-06-05 17:57:33,142 - mmdet - INFO - Epoch [1][1800/3665]	lr: 2.000e-04, eta: 13:05:34, time: 1.111, data_time: 0.256, memory: 19844, loss_rpn_cls: 0.0591, loss_rpn_bbox: 0.0693, loss_cls: 0.3040, acc: 90.5265, loss_bbox: 0.3245, loss_mask: 0.3383, loss: 1.0952
2024-06-05 17:58:26,398 - mmdet - INFO - Epoch [1][1850/3665]	lr: 2.000e-04, eta: 13:03:38, time: 1.065, data_time: 0.254, memory: 19844, loss_rpn_cls: 0.0567, loss_rpn_bbox: 0.0709, loss_cls: 0.3026, acc: 90.4998, loss_bbox: 0.3242, loss_mask: 0.3356, loss: 1.0899
2024-06-05 17:59:18,757 - mmdet - INFO - Epoch [1][1900/3665]	lr: 2.000e-04, eta: 13:01:26, time: 1.047, data_time: 0.236, memory: 19844, loss_rpn_cls: 0.0569, loss_rpn_bbox: 0.0682, loss_cls: 0.2990, acc: 90.6443, loss_bbox: 0.3180, loss_mask: 0.3374, loss: 1.0795
2024-06-05 18:00:11,870 - mmdet - INFO - Epoch [1][1950/3665]	lr: 2.000e-04, eta: 12:59:34, time: 1.062, data_time: 0.245, memory: 19844, loss_rpn_cls: 0.0561, loss_rpn_bbox: 0.0682, loss_cls: 0.2989, acc: 90.5867, loss_bbox: 0.3224, loss_mask: 0.3304, loss: 1.0760
2024-06-05 18:01:06,850 - mmdet - INFO - Exp name: mask_rcnn_efficientformer_l1_fpn_1x_coco.py
2024-06-05 18:01:06,850 - mmdet - INFO - Epoch [1][2000/3665]	lr: 2.000e-04, eta: 12:58:25, time: 1.100, data_time: 0.273, memory: 19844, loss_rpn_cls: 0.0612, loss_rpn_bbox: 0.0731, loss_cls: 0.3087, acc: 90.1897, loss_bbox: 0.3347, loss_mask: 0.3352, loss: 1.1128
2024-06-05 18:02:00,186 - mmdet - INFO - Epoch [1][2050/3665]	lr: 2.000e-04, eta: 12:56:42, time: 1.067, data_time: 0.263, memory: 19844, loss_rpn_cls: 0.0580, loss_rpn_bbox: 0.0700, loss_cls: 0.3013, acc: 90.5400, loss_bbox: 0.3199, loss_mask: 0.3322, loss: 1.0815
2024-06-05 18:02:52,643 - mmdet - INFO - Epoch [1][2100/3665]	lr: 2.000e-04, eta: 12:54:45, time: 1.049, data_time: 0.235, memory: 19844, loss_rpn_cls: 0.0577, loss_rpn_bbox: 0.0693, loss_cls: 0.2995, acc: 90.6101, loss_bbox: 0.3196, loss_mask: 0.3312, loss: 1.0772
2024-06-05 18:03:46,462 - mmdet - INFO - Epoch [1][2150/3665]	lr: 2.000e-04, eta: 12:53:16, time: 1.076, data_time: 0.226, memory: 19844, loss_rpn_cls: 0.0544, loss_rpn_bbox: 0.0682, loss_cls: 0.2887, acc: 90.7714, loss_bbox: 0.3154, loss_mask: 0.3296, loss: 1.0563
2024-06-05 18:04:39,780 - mmdet - INFO - Epoch [1][2200/3665]	lr: 2.000e-04, eta: 12:51:40, time: 1.066, data_time: 0.239, memory: 19844, loss_rpn_cls: 0.0557, loss_rpn_bbox: 0.0674, loss_cls: 0.2934, acc: 90.7410, loss_bbox: 0.3153, loss_mask: 0.3273, loss: 1.0592
2024-06-05 18:05:33,603 - mmdet - INFO - Epoch [1][2250/3665]	lr: 2.000e-04, eta: 12:50:15, time: 1.076, data_time: 0.246, memory: 19844, loss_rpn_cls: 0.0590, loss_rpn_bbox: 0.0688, loss_cls: 0.3008, acc: 90.5988, loss_bbox: 0.3203, loss_mask: 0.3276, loss: 1.0766
2024-06-05 18:06:28,527 - mmdet - INFO - Epoch [1][2300/3665]	lr: 2.000e-04, eta: 12:49:12, time: 1.098, data_time: 0.273, memory: 19844, loss_rpn_cls: 0.0559, loss_rpn_bbox: 0.0664, loss_cls: 0.2967, acc: 90.4611, loss_bbox: 0.3217, loss_mask: 0.3295, loss: 1.0701
2024-06-05 18:07:22,823 - mmdet - INFO - Epoch [1][2350/3665]	lr: 2.000e-04, eta: 12:47:58, time: 1.086, data_time: 0.288, memory: 19844, loss_rpn_cls: 0.0529, loss_rpn_bbox: 0.0698, loss_cls: 0.2957, acc: 90.6005, loss_bbox: 0.3186, loss_mask: 0.3233, loss: 1.0603
2024-06-05 18:08:15,763 - mmdet - INFO - Epoch [1][2400/3665]	lr: 2.000e-04, eta: 12:46:21, time: 1.059, data_time: 0.247, memory: 19844, loss_rpn_cls: 0.0537, loss_rpn_bbox: 0.0643, loss_cls: 0.2865, acc: 90.9532, loss_bbox: 0.3061, loss_mask: 0.3193, loss: 1.0300
2024-06-05 18:09:10,636 - mmdet - INFO - Epoch [1][2450/3665]	lr: 2.000e-04, eta: 12:45:18, time: 1.097, data_time: 0.240, memory: 19844, loss_rpn_cls: 0.0546, loss_rpn_bbox: 0.0677, loss_cls: 0.2922, acc: 90.6790, loss_bbox: 0.3169, loss_mask: 0.3204, loss: 1.0517
2024-06-05 18:10:05,798 - mmdet - INFO - Epoch [1][2500/3665]	lr: 2.000e-04, eta: 12:44:21, time: 1.103, data_time: 0.284, memory: 19844, loss_rpn_cls: 0.0593, loss_rpn_bbox: 0.0718, loss_cls: 0.3006, acc: 90.3917, loss_bbox: 0.3286, loss_mask: 0.3254, loss: 1.0858
2024-06-05 18:10:59,579 - mmdet - INFO - Epoch [1][2550/3665]	lr: 2.000e-04, eta: 12:43:01, time: 1.076, data_time: 0.251, memory: 19844, loss_rpn_cls: 0.0534, loss_rpn_bbox: 0.0667, loss_cls: 0.2921, acc: 90.6969, loss_bbox: 0.3162, loss_mask: 0.3208, loss: 1.0491
2024-06-05 18:11:52,146 - mmdet - INFO - Epoch [1][2600/3665]	lr: 2.000e-04, eta: 12:41:23, time: 1.051, data_time: 0.222, memory: 19844, loss_rpn_cls: 0.0527, loss_rpn_bbox: 0.0672, loss_cls: 0.2927, acc: 90.6101, loss_bbox: 0.3196, loss_mask: 0.3193, loss: 1.0516
2024-06-05 18:12:45,878 - mmdet - INFO - Epoch [1][2650/3665]	lr: 2.000e-04, eta: 12:40:05, time: 1.075, data_time: 0.234, memory: 19844, loss_rpn_cls: 0.0548, loss_rpn_bbox: 0.0687, loss_cls: 0.3023, acc: 90.4285, loss_bbox: 0.3221, loss_mask: 0.3240, loss: 1.0719
2024-06-05 18:13:39,010 - mmdet - INFO - Epoch [1][2700/3665]	lr: 2.000e-04, eta: 12:38:39, time: 1.063, data_time: 0.252, memory: 19844, loss_rpn_cls: 0.0540, loss_rpn_bbox: 0.0659, loss_cls: 0.2922, acc: 90.7211, loss_bbox: 0.3124, loss_mask: 0.3171, loss: 1.0416
2024-06-05 18:14:32,150 - mmdet - INFO - Epoch [1][2750/3665]	lr: 2.000e-04, eta: 12:37:14, time: 1.063, data_time: 0.225, memory: 19844, loss_rpn_cls: 0.0518, loss_rpn_bbox: 0.0653, loss_cls: 0.2874, acc: 90.7312, loss_bbox: 0.3153, loss_mask: 0.3208, loss: 1.0407
2024-06-05 18:15:26,097 - mmdet - INFO - Epoch [1][2800/3665]	lr: 2.000e-04, eta: 12:36:02, time: 1.079, data_time: 0.237, memory: 19844, loss_rpn_cls: 0.0517, loss_rpn_bbox: 0.0660, loss_cls: 0.2842, acc: 90.9172, loss_bbox: 0.3096, loss_mask: 0.3237, loss: 1.0352
2024-06-05 18:16:21,058 - mmdet - INFO - Epoch [1][2850/3665]	lr: 2.000e-04, eta: 12:35:05, time: 1.099, data_time: 0.246, memory: 19844, loss_rpn_cls: 0.0550, loss_rpn_bbox: 0.0676, loss_cls: 0.2824, acc: 90.8207, loss_bbox: 0.3133, loss_mask: 0.3217, loss: 1.0401
2024-06-05 18:17:14,952 - mmdet - INFO - Epoch [1][2900/3665]	lr: 2.000e-04, eta: 12:33:53, time: 1.078, data_time: 0.226, memory: 19844, loss_rpn_cls: 0.0537, loss_rpn_bbox: 0.0697, loss_cls: 0.2777, acc: 90.9801, loss_bbox: 0.3098, loss_mask: 0.3160, loss: 1.0269
2024-06-05 18:18:09,279 - mmdet - INFO - Epoch [1][2950/3665]	lr: 2.000e-04, eta: 12:32:48, time: 1.087, data_time: 0.249, memory: 19844, loss_rpn_cls: 0.0524, loss_rpn_bbox: 0.0645, loss_cls: 0.2848, acc: 90.7976, loss_bbox: 0.3131, loss_mask: 0.3143, loss: 1.0291
2024-06-05 18:19:04,679 - mmdet - INFO - Exp name: mask_rcnn_efficientformer_l1_fpn_1x_coco.py
2024-06-05 18:19:04,679 - mmdet - INFO - Epoch [1][3000/3665]	lr: 2.000e-04, eta: 12:31:58, time: 1.108, data_time: 0.256, memory: 19844, loss_rpn_cls: 0.0540, loss_rpn_bbox: 0.0678, loss_cls: 0.2846, acc: 90.8466, loss_bbox: 0.3132, loss_mask: 0.3178, loss: 1.0374
2024-06-05 18:19:59,178 - mmdet - INFO - Epoch [1][3050/3665]	lr: 2.000e-04, eta: 12:30:55, time: 1.090, data_time: 0.225, memory: 19844, loss_rpn_cls: 0.0508, loss_rpn_bbox: 0.0657, loss_cls: 0.2777, acc: 91.0090, loss_bbox: 0.3065, loss_mask: 0.3132, loss: 1.0138
2024-06-05 18:20:52,267 - mmdet - INFO - Epoch [1][3100/3665]	lr: 2.000e-04, eta: 12:29:34, time: 1.062, data_time: 0.229, memory: 19844, loss_rpn_cls: 0.0513, loss_rpn_bbox: 0.0634, loss_cls: 0.2842, acc: 90.9563, loss_bbox: 0.3110, loss_mask: 0.3176, loss: 1.0274
2024-06-05 18:21:46,910 - mmdet - INFO - Epoch [1][3150/3665]	lr: 2.000e-04, eta: 12:28:35, time: 1.093, data_time: 0.223, memory: 19844, loss_rpn_cls: 0.0512, loss_rpn_bbox: 0.0648, loss_cls: 0.2740, acc: 91.1674, loss_bbox: 0.2989, loss_mask: 0.3141, loss: 1.0029
